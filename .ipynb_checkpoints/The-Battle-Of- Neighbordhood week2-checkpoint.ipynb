{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Battle of Neighbourhoods - Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data acquisition and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We're scrapping the site <a href=\"https://www.point2homes.com/CA/Real-Estate-Listings/ON/Toronto.html?location=Toronto%2C+ON&search_mode=location&page=3&SelectedView=listings&LocationGeoId=783094&location_changed=&ajax=1\">point2homes.com on Toronto</a> to predict house sales on Toronto Neighbourhoods.\n",
    "2. Using  <a href='http://data.torontopolice.on.ca/datasets/mci-2014-to-2018'> The MCI  dataset includes all Major Crime Indicators (MCI) 2014 to 2018 occurrences by reported date and related offences </a>  to predict crime on Toronto Neighbourhoods.\n",
    "3. We will be completely working on <a href='https://developer.foursquare.com/'>Foursquare data</a> to explore and try to locate our new house where more venues like church, restaurant, bar, hotel museums, memorials etc.. that are present nearby."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Importing Libraries and Data Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import requests # HTTP library\n",
    "import pandas as pd # for data analysis\n",
    "import numpy as np  # data in a vectorized manner manipulation\n",
    "# Matplotlib and associated plotting modules for visualization\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm # implement statistic models\n",
    "import time # use time\n",
    "from geopy.geocoders import Nominatim  # for geocoders referencing\n",
    "import geopandas as gpd # for spatial dataset\n",
    "import seaborn as sns # for plotting and visulalization\n",
    "from scipy import stats # statistic computation\n",
    "from bs4 import BeautifulSoup # scrapping web site\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import re # regualr expression\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using user to querying the site web\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.87 Safari/537.36 Edg/80.0.100.0'\n",
    "headers={'User-Agent':user_agent} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We're scrapping the site <a href=\"https://www.point2homes.com/CA/Real-Estate-Listings/ON/Toronto.html?location=Toronto%2C+ON&search_mode=location&page=3&SelectedView=listings&LocationGeoId=783094&location_changed=&ajax=1\">point2homes.com on Toronto</a> to predict house sales on Toronto Neighbourhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrapping www.point2homes.com to retreive info\n",
    "long_list = []\n",
    "lat_list = []\n",
    "address_list = []\n",
    "price_list= []\n",
    "data_url_list = []\n",
    "bed_list = []\n",
    "bath_list = []\n",
    "bath_list = []\n",
    "sqft_list = []\n",
    "type_list = []\n",
    "# iterates in 148 pages\n",
    "for index in range(1,148):\n",
    "    url = 'https://www.point2homes.com/CA/Real-Estate-Listings/ON/Toronto.html?location=Toronto%2C+ON&search_mode=location&page={}&SelectedView=listings&LocationGeoId=783094&location_changed=&ajax=1'.format(index)\n",
    "    page = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(page.content,'html.parser')\n",
    "    time.sleep(3)\n",
    "    articles = soup.find_all('article')\n",
    "           \n",
    "    for article in articles:\n",
    "        bed = article.find(class_ = 'ic-beds')\n",
    "        if bed != None:\n",
    "            bed_list.append(bed.get_text().replace('\\n','').strip())\n",
    "        else:\n",
    "            bed_list.append('--')\n",
    "        bath = article.find(class_ = 'ic-baths')\n",
    "        if bath != None:\n",
    "            bath_list.append(bath.get_text().replace('\\n','').strip())\n",
    "        else:\n",
    "            bath_list.append('--')\n",
    "\n",
    "        sqft = article.find(class_ = 'ic-sqft')\n",
    "        if sqft != None:\n",
    "            sqft_list.append(sqft.get_text().replace('\\n','').strip())\n",
    "        else:\n",
    "            sqft_list.append('--')\n",
    "\n",
    "        typ = article.find(class_ = 'ic-proptype')\n",
    "        if typ != None:\n",
    "            type_list.append(typ.get_text().replace('\\n','').strip())\n",
    "        else:\n",
    "            type_list.append('--')\n",
    "            \n",
    "        price = article.find(class_ ='price')\n",
    "        \n",
    "        if price != None:\n",
    "            price_list.append(price['data-price'])\n",
    "        else:\n",
    "            price_list.append('--')\n",
    "        \n",
    "        address = article.find(class_ ='item-address')\n",
    "        if address != None:\n",
    "            data_url_list.append(address['data-url'])\n",
    "        else:\n",
    "            price_list.append('--')\n",
    "        \n",
    "        inputs = article.find_all('input')\n",
    "        if len(inputs) == 3:\n",
    "            address_list.append(inputs[0]['value'])\n",
    "            long_list.append(inputs[2]['value'])\n",
    "            lat_list.append(inputs[1]['value'])\n",
    "        elif len(inputs) == 2  :\n",
    "            if 'ShortAddress' in inputs[0]['id']:\n",
    "                address_list.append(inputs[0]['value'])\n",
    "                long_list.append(0)\n",
    "                lat_list.append(0)\n",
    "            elif 'ShortAddress' in inputs[1]['id']:\n",
    "                address_list.append(inputs[1]['value'])\n",
    "                long_list.append(0)\n",
    "                lat_list.append(0)\n",
    "            else:\n",
    "                address_list.append('--')\n",
    "                long_list.append(0)\n",
    "                lat_list.append(0)\n",
    "        elif len(inputs) == 1  :\n",
    "            if 'ShortAddress' in inputs[0]['id']:\n",
    "                address_list.append(inputs[0]['value'])\n",
    "                long_list.append(0)\n",
    "                lat_list.append(0)\n",
    "            else :\n",
    "                address_list.append('--')\n",
    "                long_list.append(0)\n",
    "                lat_list.append(0)\n",
    "        elif len(inputs) == 0:\n",
    "            address_list.append('--')\n",
    "            long_list.append(0)\n",
    "            lat_list.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use dictionary before use dataframe\n",
    "data_dict = dict()\n",
    "data_dict['address'] = address_list\n",
    "data_dict['long'] = long_list\n",
    "data_dict['lat'] = lat_list\n",
    "data_dict['data_url'] = data_url_list\n",
    "data_dict['price_$CAN'] = price_list\n",
    "data_dict['beds'] = bed_list\n",
    "data_dict['baths'] =bath_list\n",
    "data_dict['sqft'] = sqft_list\n",
    "data_dict['type'] = type_list\n",
    "# convert dictionary to  dataframe\n",
    "house_data = pd.DataFrame(data_dict)\n",
    "# save dataframe as csv file\n",
    "house_data.to_csv('./dataset/house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the dataframe\n",
    "house_data = pd.read_csv('./dataset/house_data.csv')\n",
    "print(house_data.shape)\n",
    "house_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use <a href='http://data.torontopolice.on.ca/datasets/mci-2014-to-2018'> The MCI  dataset includes all Major Crime Indicators (MCI) 2014 to 2018 occurrences by reported date and related offences </a>  to predict crime on Toronto Neighbourhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mci_2014_2018 = pd.read_csv('./dataset/mci_2014_to_2018.csv')\n",
    "print(mci_2014_2018.shape)\n",
    "mci_2014_2018.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We will be completely working on <a href='https://developer.foursquare.com/'>Foursquare data</a> to explore and try to locate our new house where more venues like church, restaurant, bar, hotel museums, memorials etc.. that are present nearby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'XXXXXXX' # your Foursquare ID\n",
    "CLIENT_SECRET = 'XXXXXXX' # your Foursquare Secret\n",
    "VERSION = '20191028'\n",
    "LIMIT = 150\n",
    "\n",
    "latitude = house_data.head(1).lat.values[0]  \n",
    "longitude =house_data.head(1).long.values [0]\n",
    "toronto='Toronto location : {},{}'.format(latitude,longitude)\n",
    "print(toronto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quering for hotel & restaurant\n",
    "\n",
    "search_query = 'hotel'\n",
    "search_query_res = 'restaurant'\n",
    "\n",
    "radius = 1000\n",
    "url_hotel = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude, VERSION, search_query, radius, LIMIT)\n",
    "url_restaurant = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude, VERSION, search_query_res, radius, LIMIT)\n",
    "#url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hotel = requests.get(url_hotel).json()\n",
    "results_restaurant = requests.get(url_restaurant).json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the dataframe\n",
    "house_data = pd.read_csv('./dataset/house_data.csv')\n",
    "print(house_data.shape)\n",
    "house_data['neighborhood'] = np.nan\n",
    "for i in range(0,house_data.shape[0]):\n",
    "    house_data.loc[i,'neighborhood']= house_data.loc[i,'data_url'].split('/')[5]\n",
    "\n",
    "# remove  text in columns ['beds','baths','sqft',''price_$CAN]\n",
    "house_data.beds = house_data.beds.apply(lambda x: re.sub('\\D','',x))\n",
    "house_data.baths = house_data.baths.apply(lambda x: re.sub('\\D','',x))\n",
    "house_data['price_$CAN'] = house_data['price_$CAN'].apply(lambda x: re.sub('\\D','',x) )\n",
    "house_data.sqft = house_data.sqft.apply(lambda x: re.sub('\\D','',x))\n",
    "\n",
    "#rename the price_$CAN to price_dallar_can\n",
    "house_data.rename(columns ={'price_$CAN':'price_dallar_can'},inplace =True)\n",
    "\n",
    "# remove (-) in neignborhood columns\n",
    "house_data.neighborhood = house_data.neighborhood.str.replace('-',' ')\n",
    "\n",
    "\n",
    "# drop columns ['data_url','Unnamed: 0']\n",
    "house_data.drop(columns =['data_url','Unnamed: 0'],axis=1,inplace =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter null value of ['beds','baths','sqft']\n",
    "house_data = house_data.loc[house_data['beds']!= '' ]\n",
    "house_data = house_data.loc[house_data['baths']!= '' ]\n",
    "house_data = house_data.loc[house_data['sqft']!= '' ]\n",
    "house_data[['price_dallar_can','beds','baths','sqft']] = house_data[['price_dallar_can','beds','baths','sqft']].astype('int')\n",
    "print(house_data.shape)\n",
    "house_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df =pd.get_dummies(house_data.type)\n",
    "type_df.head()\n",
    "house_data['Apartment']=type_df.Apartment\n",
    "house_data['Condo']=type_df.Condo\n",
    "house_data['Residential']=type_df.Residential\n",
    "house_data['Townhouse']=type_df.Townhouse\n",
    "neighborhood_house_data = house_data.groupby(['neighborhood']).mean()\n",
    "neighborhood_house_data.reset_index(inplace =True)\n",
    "neighborhood_house_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mci_2014_2018 = pd.read_csv('./dataset/mci_2014_to_2018.csv')\n",
    "print(mci_2014_2018.shape)\n",
    "mci_2014_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mci_2014_2018.head(10)\n",
    "MCI = pd.get_dummies(mci_2014_2018.MCI)\n",
    "MCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Calculation of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
